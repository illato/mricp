{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5670e85d-cd3d-4df7-ba47-53d96cd48fae",
   "metadata": {},
   "source": [
    "- `conda activate mri`\n",
    "  - (created in `0_setup.ipynb`)\n",
    "\n",
    "---\n",
    "\n",
    "- `jupyter lab` => open this file\n",
    "\n",
    "---\n",
    "\n",
    "- Selected Jupyter kernel (`ms_classification`)\n",
    "  - (created in `0_setup.ipynb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5947de17-5b11-43ba-8fc3-0fde5b594e9a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d3a13b-fefe-4bdd-a038-1e75b51025ef",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176729cd-b872-4eba-b9f4-78d1bbbca822",
   "metadata": {},
   "source": [
    "# Experimental Setup Overview\n",
    "\n",
    "We evaluate two conformal prediction approaches—**Standard (Marginal)** and **Class-Conditional**—across:\n",
    "\n",
    "- **8 dataset variants**  \n",
    "- **4 calibration/test distribution pairings**  \n",
    "  - 2 expected to satisfy CP assumptions  \n",
    "  - 2 designed to violate CP assumptions  \n",
    "- **100 Monte Carlo splits** per configuration  \n",
    "\n",
    "> **Total runs per configuration:**  \n",
    "> 2 approaches × 8 variants × 4 cal/test pairings × 100 splits = **6,400 runs**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c08f39-56c3-467b-963d-cb40c91ffb4c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aca7472-8a8b-4768-9e56-1f306903f18d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef55fe5-1d52-4793-a206-55daa0b2a08a",
   "metadata": {},
   "source": [
    "# Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2fdfa8-1207-43f6-828f-63af2f8a3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing   import Callable, Optional, List\n",
    "import numpy as np, pandas as pd, conformal, util\n",
    "\n",
    "df3 = pd.read_pickle('all_unseen_3T_variant_scans_preds_for_baseline_model.pkl')\n",
    "df15 = pd.read_pickle('all_unseen_15T_variant_scans_preds_for_baseline_model.pkl')\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 1.  describe each experiment once, declaratively\n",
    "# --------------------------------------------------------------------\n",
    "@dataclass\n",
    "class Setup:\n",
    "    label:           str                         # “baseline3T‑cal_dv3T‑test”, …\n",
    "    cal_variant:     Optional[str]              # None = “match test variant”\n",
    "    cal_df:          pd.DataFrame               # calibration source dataframe\n",
    "    test_df:         pd.DataFrame               # test‑set source dataframe\n",
    "    is_ms_cal:       Callable[[str], bool]      # helper to flag MS scans\n",
    "    is_ms_test:      Callable[[str], bool]\n",
    "\n",
    "setups: List[Setup] = [\n",
    "    Setup('dv3T-cal_dv3T-test',     None,      df3,     df3,\n",
    "          lambda s: '_' in s,                  lambda s: '_' in s),\n",
    "    Setup('baseline3T-cal_dv3T-test', 'baseline', df3,  df3,\n",
    "          lambda s: '_' in s,                  lambda s: '_' in s),\n",
    "    Setup('baseline3T-cal_dv1.5T-test', 'baseline', df3, df15,\n",
    "          lambda s: '_' in s,                  lambda s: len(s) <= 2),\n",
    "    Setup('dv1.5T-cal_dv1.5T-test',  None,      df15,  df15,\n",
    "          lambda s: len(s) <= 2,               lambda s: len(s) <= 2),\n",
    "]\n",
    "\n",
    "NUM_SELECT = 42\n",
    "util.set_seeds()\n",
    "\n",
    "all_counts, all_cp = [], []\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 2.  shared inner routine – run CP once for one (cal,test) pair\n",
    "# --------------------------------------------------------------------\n",
    "def run_cp(cal: pd.DataFrame, test: pd.DataFrame):\n",
    "    \"\"\"Return ordinary and class‑conditional CP results concatenated.\"\"\"\n",
    "    cp = conformal.conformal_prediction(cal,  test, verbose=False,\n",
    "                                        alpha=0.10, class_conditional=False)\n",
    "    cc = conformal.conformal_prediction(cal,  test, verbose=False,\n",
    "                                        alpha=0.10, class_conditional=True)\n",
    "    return pd.concat([cp, cc], ignore_index=True)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 3.  main experiment loop\n",
    "# --------------------------------------------------------------------\n",
    "for st in setups:\n",
    "    ids_cal  = st.cal_df['scan_id'].unique()\n",
    "    ids_test = st.test_df['scan_id'].unique()\n",
    "\n",
    "    for run in range(100):\n",
    "        # calibration needs to contain both classes -> sample IDs with retry logic\n",
    "        cal_ids, final_seed = util.select_calibration_ids_with_class_check(ids_cal, st, NUM_SELECT, run)\n",
    "        ids_test_no_intersect = np.setdiff1d(ids_test, cal_ids, assume_unique=True)\n",
    "        rng = np.random.default_rng(final_seed)  # Ensure test selection uses the final seed\n",
    "        test_ids = rng.choice(ids_test_no_intersect, len(ids_test) - NUM_SELECT, replace=False)\n",
    "\n",
    "        # bookkeeping ------------------------------------------------\n",
    "        def count(ids, fn): return sum(fn(x) for x in ids)\n",
    "        cal_ms, test_ms = count(cal_ids, st.is_ms_cal), count(test_ids, st.is_ms_test)\n",
    "        all_counts.append({\n",
    "            \"cal_test\": st.label, \"run\": run,\n",
    "            \"cal_num_ms_scans\": cal_ms,\n",
    "            \"cal_num_healthy_scans\": NUM_SELECT - cal_ms,\n",
    "            \"cal_num_total_scans\": NUM_SELECT,\n",
    "            \"test_num_ms_scans\": test_ms,\n",
    "            \"test_num_healthy_scans\": len(test_ids) - test_ms,\n",
    "            \"test_num_total_scans\": len(test_ids)\n",
    "        })\n",
    "\n",
    "        # CP for every variant ---------------------------------------\n",
    "        for vtd in st.test_df['variant_test_data'].unique():\n",
    "            cvtd = vtd if st.cal_variant is None else st.cal_variant\n",
    "\n",
    "            cal_slice  = st.cal_df.query(\n",
    "                \"variant_test_data == @cvtd and scan_id in @cal_ids\")\n",
    "            test_slice = st.test_df.query(\n",
    "                \"variant_test_data == @vtd and  scan_id in @test_ids\")\n",
    "\n",
    "            cp_res = run_cp(cal_slice, test_slice)\n",
    "            cp_res[\"run\"] = run\n",
    "            cp_res[\"cal_test\"] = st.label\n",
    "            all_cp.append(cp_res)\n",
    "\n",
    "# final dataframes\n",
    "counts_df   = pd.DataFrame(all_counts)\n",
    "df_combined = pd.concat(all_cp, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b90102-7073-4585-998b-b74fcc400677",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6174dcb-14bf-4fd3-b996-120f7609255f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830820d9-e476-4157-b996-112b4bff2a30",
   "metadata": {},
   "source": [
    "# Run Overall Baseline Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d72a31-205f-43e4-b782-7e1c11438f66",
   "metadata": {},
   "source": [
    "Minimal script:  \n",
    "\n",
    "100 Monte-Carlo runs of conformal prediction for the *baseline* `variant_test_data`,  \n",
    "pulling calibration **and** test from the union of the 3 T and 1.5 T prediction tables.  \n",
    "\n",
    "- cal ∩ test = ∅  \n",
    "- calibration sample (NUM_SELECT) must contain both classes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627a1f31-8ceb-45f9-b13e-3c5c83479ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 16:42:03.642106: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-26 16:42:03.672681: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750977723.692495 1050975 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750977723.698551 1050975 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-26 16:42:03.719074: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#\n",
    "# Illustration code producing only 'baseline' result subset of above code cell (makes it easier to see what's going on)\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "# from __future__ import annotations\n",
    "# import numpy as np, pandas as pd, conformal, util\n",
    "\n",
    "# # ────────────────────────────────────────────────────────────────────────────────\n",
    "# # 0.  load & combine prediction tables\n",
    "# # ────────────────────────────────────────────────────────────────────────────────\n",
    "# df3  = pd.read_pickle(\"all_unseen_3T_variant_scans_preds_for_baseline_model.pkl\")\n",
    "# df15 = pd.read_pickle(\"all_unseen_15T_variant_scans_preds_for_baseline_model.pkl\")\n",
    "# all_df = pd.concat([df3, df15], ignore_index=True)\n",
    "\n",
    "# BASELINE    = \"baseline\"   # the only variant we evaluate\n",
    "# NUM_SELECT  = 42\n",
    "# N_RUNS      = 100\n",
    "\n",
    "# util.set_seeds()\n",
    "\n",
    "\n",
    "# # ────────────────────────────────────────────────────────────────────────────────\n",
    "# # 1.  helper: draw a calibration id set that contains both classes\n",
    "# # ────────────────────────────────────────────────────────────────────────────────\n",
    "# def pick_calibration_ids(ids: np.ndarray,\n",
    "#                          df: pd.DataFrame,\n",
    "#                          k: int,\n",
    "#                          run: int,\n",
    "#                          max_attempts: int = 1_000) -> tuple[np.ndarray, int]:\n",
    "#     \"\"\"\n",
    "#     Re-sample until the chosen `k` IDs contain at least one 0 and one 1 in `class`.\n",
    "#     Seed escalates by 1000 each retry so test sampling remains reproducible.\n",
    "#     \"\"\"\n",
    "#     for attempt in range(max_attempts):\n",
    "#         seed = run + attempt * 1000\n",
    "#         rng  = np.random.default_rng(seed)\n",
    "#         cal_ids = rng.choice(ids, k, replace=False)\n",
    "\n",
    "#         if {0, 1}.issubset(df.loc[df.scan_id.isin(cal_ids), \"class\"].unique()):\n",
    "#             return cal_ids, seed\n",
    "\n",
    "#     raise RuntimeError(\n",
    "#         f\"Could not obtain both classes after {max_attempts} attempts (run={run}).\"\n",
    "#     )\n",
    "\n",
    "\n",
    "# # ────────────────────────────────────────────────────────────────────────────────\n",
    "# # 2.  core CP wrapper (ordinary + class-conditional)\n",
    "# # ────────────────────────────────────────────────────────────────────────────────\n",
    "# def run_cp(cal: pd.DataFrame, test: pd.DataFrame) -> pd.DataFrame:\n",
    "#     cp  = conformal.conformal_prediction(cal, test, alpha=0.10,\n",
    "#                                          class_conditional=False, verbose=False)\n",
    "#     ccp = conformal.conformal_prediction(cal, test, alpha=0.10,\n",
    "#                                          class_conditional=True,  verbose=False)\n",
    "#     return pd.concat([cp, ccp], ignore_index=True)\n",
    "\n",
    "\n",
    "# # ────────────────────────────────────────────────────────────────────────────────\n",
    "# # 3.  Monte-Carlo loop (= 100 disjoint cal/test splits)\n",
    "# # ────────────────────────────────────────────────────────────────────────────────\n",
    "# ids_pool   = all_df[\"scan_id\"].unique()\n",
    "# results    = []\n",
    "# split_meta = []\n",
    "\n",
    "# for run in range(N_RUNS):\n",
    "#     cal_ids, seed = pick_calibration_ids(ids_pool, all_df, NUM_SELECT, run)\n",
    "#     test_ids      = np.setdiff1d(ids_pool, cal_ids, assume_unique=True)\n",
    "\n",
    "#     cal_slice  = all_df.loc[(all_df.scan_id.isin(cal_ids))  &\n",
    "#                             (all_df.variant_test_data == BASELINE)]\n",
    "#     test_slice = all_df.loc[(all_df.scan_id.isin(test_ids)) &\n",
    "#                             (all_df.variant_test_data == BASELINE)]\n",
    "\n",
    "#     # If the baseline subset is too small, skip the run (rare but explicit)\n",
    "#     if cal_slice.empty or test_slice.empty:\n",
    "#         continue\n",
    "\n",
    "#     res = run_cp(cal_slice, test_slice)\n",
    "#     res[\"run\"] = run\n",
    "#     results.append(res)\n",
    "\n",
    "#     split_meta.append({\n",
    "#         \"run\": run,\n",
    "#         \"seed\": seed,\n",
    "#         \"num_cal\": len(cal_slice),\n",
    "#         \"num_test\": len(test_slice),\n",
    "#         \"cal_ids\": cal_ids.tolist(),   # keep for reproducibility / debugging\n",
    "#         \"test_ids\": test_ids.tolist()\n",
    "#     })\n",
    "\n",
    "# # make dfs\n",
    "# cp_df     = pd.concat(results, ignore_index=True)\n",
    "# splits_df = pd.DataFrame(split_meta)\n",
    "\n",
    "# # save dfs\n",
    "# cp_df.to_pickle(\"baseline_cp_results.pkl\")\n",
    "# splits_df.to_pickle(\"baseline_split_metadata.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c40ffdb-b6e4-475a-8463-bf8a84acf2bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea99319a-60ec-4589-aeda-0b6cd92c27b6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec06c90b-e966-407b-8964-6a95d5e134d2",
   "metadata": {},
   "source": [
    "# Aggregate Conformal Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99d2717a-a85c-4486-bcd8-5b89602a00d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Per-run by class: mean for some, median for others ---\n",
    "runs_by_class = (\n",
    "    df_combined\n",
    "    .groupby(\n",
    "        [\"class_conditional\", \"variant_test_data\", \"cal_test\", \"run\", \"class\"],\n",
    "        as_index=False\n",
    "    )\n",
    "    .agg({\n",
    "        \"is_correct\": \"mean\",\n",
    "        \"verdict\":    \"mean\",\n",
    "        \"ps_size\":    \"mean\",\n",
    "        \"confidence\": \"median\",\n",
    "        \"credibility\":\"median\",\n",
    "        \"margin\":     \"median\",\n",
    "        \"actual_class_pred_prob\": \"median\"\n",
    "    })\n",
    ")\n",
    "\n",
    "# --- 2) Per-run overall (across both classes) ---\n",
    "runs_overall = (\n",
    "    df_combined\n",
    "    .groupby(\n",
    "        [\"class_conditional\", \"variant_test_data\", \"cal_test\", \"run\"],\n",
    "        as_index=False\n",
    "    )\n",
    "    .agg({\n",
    "        \"is_correct\": \"mean\",\n",
    "        \"verdict\":    \"mean\",\n",
    "        \"ps_size\":    \"mean\",\n",
    "        \"confidence\": \"median\",\n",
    "        \"credibility\":\"median\",\n",
    "        \"margin\":     \"median\",\n",
    "        \"actual_class_pred_prob\": \"median\"\n",
    "    })\n",
    ")\n",
    "runs_overall[\"class\"] = \"all\"\n",
    "\n",
    "# --- 3) Combine per-run DataFrame ---\n",
    "runs = pd.concat([runs_by_class, runs_overall], ignore_index=True)\n",
    "\n",
    "# --- 4) Per-run class-1 proportion ---\n",
    "prop1 = (\n",
    "    df_combined\n",
    "    .assign(is1 = lambda df: df[\"class\"] == 1)\n",
    "    .groupby([\"class_conditional\", \"variant_test_data\", \"cal_test\", \"run\"], as_index=False)\n",
    "    .agg(prop_class1 = (\"is1\", \"mean\"))\n",
    ")\n",
    "runs = runs.merge(prop1, on=[\"class_conditional\", \"variant_test_data\", \"cal_test\", \"run\"])\n",
    "\n",
    "# --- 5) Across-runs summary ---\n",
    "summary = (\n",
    "    runs\n",
    "    .groupby(\n",
    "        [\"class_conditional\", \"variant_test_data\", \"cal_test\", \"class\"],\n",
    "        as_index=False\n",
    "    )\n",
    "    .agg({\n",
    "        # medians of the per-run means\n",
    "        \"is_correct\":             \"median\",\n",
    "        \"verdict\":                \"median\",\n",
    "        \"ps_size\":                \"median\",\n",
    "        # medians of the per-run medians\n",
    "        \"confidence\":             \"median\",\n",
    "        \"credibility\":            \"median\",\n",
    "        \"margin\":                 \"median\",\n",
    "        \"actual_class_pred_prob\": \"median\",\n",
    "        # proportion of class 1\n",
    "        \"prop_class1\":            \"median\",\n",
    "        # count of runs\n",
    "        \"run\":                    \"nunique\"\n",
    "    })\n",
    "    .rename(columns={\"run\": \"runs_count\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e52374-1514-4dbf-bac1-e1bb1f416cab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec655ab-1a1b-4355-a8bf-658471358ce5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7b5919-b299-4a06-b62c-8bdde6549fb0",
   "metadata": {},
   "source": [
    "# Write Instance-Level Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb49dfb-e30d-4902-a850-c271a35e5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_pickle('___4x_cal-test_combos__100x_cp__per_variant_test_data__cp_instance_col.pkl')\n",
    "df_combined.drop(columns=['cp']).to_csv('___4x_cal-test_combos__100x_cp__per_variant_test_data.csv', index=False)\n",
    "counts_df.to_csv('___4x_cal-test_combos__100x_cp__per_variant_test_data__ms_vs_healthy_scan_cnt_per_config_run.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea76ef39-2543-412c-8975-f2a503d36bcf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72424d34-d29c-40c5-aeae-671b0f55bbf9",
   "metadata": {},
   "source": [
    "# Write Aggregate Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81502484-fed5-49a0-aacd-c0ca85b783d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip leading/trailing underscore\n",
    "runs['variant_test_data'] = runs['variant_test_data'].apply(lambda x: x.strip('_'))\n",
    "summary['variant_test_data'] = summary['variant_test_data'].apply(lambda x: x.strip('_'))\n",
    "\n",
    "# write per-run files\n",
    "runs[(runs.class_conditional==False) & (runs['class']=='all')].to_csv('___conformal_measures__runs__marginal.csv', index=False)\n",
    "runs[(runs.class_conditional==False) & (runs['class']!='all')].to_csv('___conformal_measures__runs__marginal__by_class.csv', index=False)\n",
    "runs[(runs.class_conditional==True) & (runs['class']=='all')].to_csv( '___conformal_measures__runs__class_conditional.csv', index=False)\n",
    "runs[(runs.class_conditional==True) & (runs['class']!='all')].to_csv( '___conformal_measures__runs__class_conditional__by_class.csv', index=False)\n",
    "\n",
    "# write across-runs files\n",
    "summary[(summary.class_conditional==False) & (summary['class']=='all')].to_csv('___conformal_measures__summary__marginal.csv', index=False)\n",
    "summary[(summary.class_conditional==False) & (summary['class']!='all')].to_csv('___conformal_measures__summary__marginal__by_class.csv', index=False)\n",
    "summary[(summary.class_conditional==True) & (summary['class']=='all')].to_csv( '___conformal_measures__summary__class_conditional.csv', index=False)\n",
    "summary[(summary.class_conditional==True) & (summary['class']!='all')].to_csv( '___conformal_measures__summary__class_conditional__by_class.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b7195-b169-4a33-b9fe-1efe3989d93a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ff6703-e9c9-4816-a81e-e9a5711d786e",
   "metadata": {},
   "source": [
    "# Read Aggregate Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06e2da43-2d6f-407d-88d4-c967ef278cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = pd.read_csv(   '___conformal_measures__runs__marginal.csv')\n",
    "summary = pd.read_csv('___conformal_measures__summary__marginal.csv')\n",
    "\n",
    "runs_by_class = pd.read_csv(   '___conformal_measures__runs__marginal__by_class.csv')\n",
    "summary_by_class = pd.read_csv('___conformal_measures__summary__marginal__by_class.csv')\n",
    "\n",
    "runs_cc = pd.read_csv(   '___conformal_measures__runs__class_conditional.csv')\n",
    "summary_cc = pd.read_csv('___conformal_measures__summary__class_conditional.csv')\n",
    "\n",
    "runs_cc_by_class = pd.read_csv(   '___conformal_measures__runs__class_conditional__by_class.csv')\n",
    "summary_cc_by_class = pd.read_csv('___conformal_measures__summary__class_conditional__by_class.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559491a5-02b8-42ff-9360-9524a0219af1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131416a8-e158-416d-8031-cb5c79e03546",
   "metadata": {},
   "source": [
    "# Read Instance-Level Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c9442ab-08d8-45ad-86ea-19a2b98d3755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_pickle('___4x_cal-test_combos__100x_cp__per_variant_test_data__cp_instance_col.pkl')\n",
    "counts_df = pd.read_csv('___4x_cal-test_combos__100x_cp__per_variant_test_data__ms_vs_healthy_scan_cnt_per_config_run.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60424a1a-0afe-40c5-ba6c-c6b6bdc6d3f6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd9166-b9fe-461d-b6be-d2b93a9a1e1b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f4479-665c-464f-9445-e9fc0de5021c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ef110-edeb-4f52-9c04-2cab4f6616f4",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ms_classification)",
   "language": "python",
   "name": "ms_classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
